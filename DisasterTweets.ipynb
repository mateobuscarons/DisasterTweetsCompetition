{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary libraries and packages to execute the notebook. "
      ],
      "metadata": {
        "id": "0Wz1y3vdjWKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "czBb70ZLlvfK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code reads in three CSV files: train data, test data, and a sample submission file for the competition."
      ],
      "metadata": {
        "id": "2DoqE6n8hNcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('train.csv', dtype={'id': np.int16, 'target': np.int8})\n",
        "df_test = pd.read_csv('test.csv', dtype={'id': np.int16})\n",
        "submission = pd.read_csv(\"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "68uBN_WfotoS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how the data looks like:"
      ],
      "metadata": {
        "id": "YTPrh3SkhZCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dPGXULQqQtq6",
        "outputId": "a1d6fc25-b7b1-46ea-c268-dd17aa925915"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN            Deeds Reason # earthquake ALLAH Forgive   \n",
              "1   4     NaN      NaN            Forest fire near La Ronge Sask . Canada   \n",
              "2   5     NaN      NaN  residents asked ' shelter place ' notified off...   \n",
              "3   6     NaN      NaN  13,000 people receive # wildfires evacuation o...   \n",
              "4   7     NaN      NaN  got sent photo Ruby # Alaska smoke # wildfires...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f65e0ff6-bc81-4c6a-94e2-c998d6545406\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Deeds Reason # earthquake ALLAH Forgive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask . Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>residents asked ' shelter place ' notified off...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive # wildfires evacuation o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>got sent photo Ruby # Alaska smoke # wildfires...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f65e0ff6-bc81-4c6a-94e2-c998d6545406')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f65e0ff6-bc81-4c6a-94e2-c998d6545406 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f65e0ff6-bc81-4c6a-94e2-c998d6545406');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_text = df_train.text.values\n",
        "df_train_labels = df_train.target.values\n",
        "df_test_text = df_test.text.values"
      ],
      "metadata": {
        "id": "9jIrobCWQt3A"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the en_core_web_sm module from the spaCy library and using it to define a function remove_stopwords() which takes a list of training data and removes all the stop words from it using spaCy's natural language processing capabilities. The function is then called on a sample training data to demonstrate the removal of stop words."
      ],
      "metadata": {
        "id": "lSfnq1-_hiJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import en_core_web_sm\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "def remove_stopwords(training_data, nlp):\n",
        "    stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
        "                 \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\",\n",
        "                 \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\",\n",
        "                 \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\",\n",
        "                 \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\",\n",
        "                 \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\",\n",
        "                 \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\",\n",
        "                 \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\",\n",
        "                 \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\",\n",
        "                 \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\",\n",
        "                 \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "                 \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\",\n",
        "                 \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]\n",
        "        \n",
        "    for k in range(len(training_data)):\n",
        "        sentence = training_data[k]\n",
        "        doc = nlp(sentence)\n",
        "        tokens = [token.text for token in doc]\n",
        "        filtered = [token.text for token in doc if token.is_stop == False]\n",
        "        sentence = \" \".join(filtered)\n",
        "        training_data[k] = sentence\n",
        "    \n",
        "    return training_data\n",
        "\n",
        "print(\"Before cleaning: \",df_train_text[0])\n",
        "df_train_text = remove_stopwords(df_train_text, nlp)\n",
        "print(\"After cleaning: \",df_train_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgPwqcNIQt58",
        "outputId": "5ce77bae-12aa-4bee-cdc1-3ad6a74604e9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before cleaning:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "After cleaning:  Deeds Reason # earthquake ALLAH Forgive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into training split and validation split:"
      ],
      "metadata": {
        "id": "S_1qvJ8ahyUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_SPLIT = 0.7\n",
        "\n",
        "def train_val_split(texts, labels, training_split):\n",
        "    \n",
        "    train_size = int(len(texts)*training_split)\n",
        "    \n",
        "    train_texts = texts[:train_size]\n",
        "    train_labels = labels[:train_size]\n",
        "    \n",
        "    validation_texts = texts[train_size:]\n",
        "    validation_labels = labels[train_size:]\n",
        "    \n",
        "    return train_texts, validation_texts, train_labels, validation_labels\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_val_split(df_train_text, df_train_labels, TRAINING_SPLIT)"
      ],
      "metadata": {
        "id": "HUD3goAWQt8D"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen model is a simple ***neural network*** with an embedding layer followed by a global average pooling layer, two dense layers (with 64 and 1 units respectively), and a dropout layer in between to prevent overfitting. The model is compiled with the Adam optimizer and binary cross-entropy loss, and the accuracy is used as the evaluation metric.\n",
        "\n",
        "The hyperparameters were chosen as follows:\n",
        "\n",
        "**NUM_WORDS** = 10000: the number of words to keep in the tokenizer's word index based on frequency.\n",
        "\n",
        "**OOV_TOKEN** = \"<OOV>\": a special token to replace words that are not in the tokenizer's word index.\n",
        "\n",
        "**MAXLEN** = 120: the maximum length of the input sequences, which are padded or truncated to this length.\n",
        "\n",
        "**PADDING** = 'post': the padding strategy for the sequences, which pads zeros at the end of the sequences.\n",
        "\n",
        "**EMBEDDING_DIM** = 128: the dimensionality of the dense embedding layer, which determines the number of features in the embedding vectors.\n",
        "\n",
        "**EPOCHS** = 100: the number of times the model trains on the entire dataset.\n",
        "\n",
        "**BATCH_SIZE** = 32: the number of samples processed by the model in each training batch."
      ],
      "metadata": {
        "id": "NtD7nC6aig55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "NUM_WORDS = 10000\n",
        "OOV_TOKEN = \"<OOV>\"\n",
        "MAXLEN = 120\n",
        "PADDING = 'post'\n",
        "EMBEDDING_DIM = 128\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAXLEN))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = model.fit(train_padded_seq, train_labels, batch_size=BATCH_SIZE, \n",
        "                    epochs=EPOCHS, validation_data=(val_padded_seq, val_labels), callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iXGTbfhUjkR",
        "outputId": "7a10340b-221b-4f63-f9ab-64f406ed908b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "167/167 [==============================] - 5s 25ms/step - loss: 0.6806 - accuracy: 0.5755 - val_loss: 0.6834 - val_accuracy: 0.5582\n",
            "Epoch 2/100\n",
            "167/167 [==============================] - 5s 30ms/step - loss: 0.6674 - accuracy: 0.5765 - val_loss: 0.6614 - val_accuracy: 0.5578\n",
            "Epoch 3/100\n",
            "167/167 [==============================] - 4s 24ms/step - loss: 0.5996 - accuracy: 0.6891 - val_loss: 0.6008 - val_accuracy: 0.7080\n",
            "Epoch 4/100\n",
            "167/167 [==============================] - 4s 23ms/step - loss: 0.4728 - accuracy: 0.8032 - val_loss: 0.5142 - val_accuracy: 0.7526\n",
            "Epoch 5/100\n",
            "167/167 [==============================] - 5s 28ms/step - loss: 0.3709 - accuracy: 0.8512 - val_loss: 0.4718 - val_accuracy: 0.7929\n",
            "Epoch 6/100\n",
            "167/167 [==============================] - 4s 24ms/step - loss: 0.3051 - accuracy: 0.8816 - val_loss: 0.4662 - val_accuracy: 0.7894\n",
            "Epoch 7/100\n",
            "167/167 [==============================] - 4s 25ms/step - loss: 0.2695 - accuracy: 0.9020 - val_loss: 0.4833 - val_accuracy: 0.7666\n",
            "Epoch 8/100\n",
            "167/167 [==============================] - 5s 29ms/step - loss: 0.2323 - accuracy: 0.9169 - val_loss: 0.5123 - val_accuracy: 0.7820\n",
            "Epoch 9/100\n",
            "167/167 [==============================] - 4s 24ms/step - loss: 0.2031 - accuracy: 0.9278 - val_loss: 0.5046 - val_accuracy: 0.7701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model is ready, this prepares the submission document for the competition by applying the prediction with the test dataframe. "
      ],
      "metadata": {
        "id": "HqCSAm0niz2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_pred = remove_stopwords(df_test_text, nlp)\n",
        "test_padded_seq = seq_and_pad(df_test_pred, tokenizer, PADDING, MAXLEN)\n",
        "df_test_pred = model.predict(test_padded_seq)\n",
        "submission['target'] = df_test_pred.round().astype(int)\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ52L6nzRQ-f",
        "outputId": "64bdff6f-a8db-4a3a-ae54-8cfc246f64c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    }
  ]
}